"""
Exemples avanc√©s d'utilisation du RAG
Montre diff√©rents cas d'usage et patterns
"""

import asyncio
import sys
from pathlib import Path

sys.path.insert(0, str(Path(__file__).parent))

from backend.rag.rag_helper import rag_helper, answer_question_with_rag


# ============================================================
# EXEMPLE 1 : Base de connaissances multi-th√®mes
# ============================================================

async def example_knowledge_base():
    """Cr√©er une base de connaissances avec plusieurs th√©matiques"""
    
    print("=" * 60)
    print("üìö EXEMPLE 1 : Base de connaissances multi-th√®mes")
    print("=" * 60)
    print()
    
    # D√©finir les connaissances
    knowledge = {
        "python": {
            "basics.txt": """
Python est un langage interpr√©t√© de haut niveau.
Les variables n'ont pas besoin de d√©claration de type.
L'indentation est significative en Python.
Python supporte la POO, la programmation fonctionnelle et imp√©rative.
            """,
            "data_structures.txt": """
Python offre plusieurs structures de donn√©es natives :
- list : tableau dynamique modifiable
- tuple : s√©quence immuable
- dict : table de hachage (cl√©-valeur)
- set : ensemble d'√©l√©ments uniques
            """
        },
        "fastapi": {
            "intro.txt": """
FastAPI est un framework web moderne pour Python.
Il est bas√© sur les standards Python type hints.
FastAPI g√©n√®re automatiquement une documentation OpenAPI.
Il utilise Pydantic pour la validation des donn√©es.
            """,
            "routes.txt": """
Les routes FastAPI sont d√©cor√©es avec @app.get(), @app.post(), etc.
On peut d√©finir des param√®tres de path, query et body.
FastAPI supporte les requ√™tes asynchrones avec async/await.
            """
        }
    }
    
    # Ajouter tous les documents
    print("üìù Ajout des documents...")
    for dataset, files in knowledge.items():
        for filename, content in files.items():
            doc_id = rag_helper.add_document_sync(
                dataset=dataset,
                filename=filename,
                content=content.strip()
            )
            print(f"   ‚úÖ {dataset}/{filename}")
    
    print()
    
    # Poser des questions sur diff√©rents datasets
    questions = [
        ("python", "Quelles sont les structures de donn√©es natives ?"),
        ("fastapi", "Comment d√©finir des routes ?"),
    ]
    
    print("üîç Questions et r√©ponses :")
    print()
    
    for dataset, question in questions:
        print(f"   Dataset: {dataset}")
        print(f"   Q: {question}")
        
        answer = await answer_question_with_rag(
            dataset=dataset,
            question=question,
            top_k=3
        )
        
        print(f"   R: {answer[:200]}...")
        print()


# ============================================================
# EXEMPLE 2 : Documentation de code
# ============================================================

async def example_code_documentation():
    """Documenter et interroger du code"""
    
    print("=" * 60)
    print("üíª EXEMPLE 2 : Documentation de code")
    print("=" * 60)
    print()
    
    # Code source √† documenter
    code_files = {
        "user_model.py": """
class User:
    def __init__(self, username: str, email: str):
        self.username = username
        self.email = email
        self.is_active = True
    
    def deactivate(self):
        '''D√©sactive l'utilisateur'''
        self.is_active = False
    
    def validate_email(self) -> bool:
        '''V√©rifie que l'email est valide'''
        return '@' in self.email
        """,
        "auth_service.py": """
class AuthService:
    def login(self, username: str, password: str) -> Token:
        '''Authentifie un utilisateur et retourne un token JWT'''
        user = self.find_user(username)
        if not user or not self.verify_password(password):
            raise AuthenticationError()
        return self.create_token(user)
    
    def logout(self, token: str):
        '''Invalide un token d'authentification'''
        self.blacklist_token(token)
        """
    }
    
    print("üìù Ajout du code au RAG...")
    for filename, code in code_files.items():
        rag_helper.add_document_sync(
            dataset="codebase",
            filename=filename,
            content=code.strip(),
            metadata={"type": "python_code"}
        )
        print(f"   ‚úÖ {filename}")
    
    print()
    
    # Interroger le code
    questions = [
        "Comment d√©sactiver un utilisateur ?",
        "Quelle m√©thode permet de se connecter ?",
        "Comment valider un email ?"
    ]
    
    print("üîç Questions sur le code :")
    print()
    
    for question in questions:
        print(f"   Q: {question}")
        result = await rag_helper.answer_with_rag(
            dataset="codebase",
            question=question,
            top_k=2
        )
        print(f"   R: {result['answer']}")
        print()


# ============================================================
# EXEMPLE 3 : Recherche contextuelle
# ============================================================

async def example_contextual_search():
    """Recherche avec contexte et filtrage"""
    
    print("=" * 60)
    print("üîé EXEMPLE 3 : Recherche contextuelle avanc√©e")
    print("=" * 60)
    print()
    
    # Base de donn√©es produits
    products = [
        {
            "name": "laptop_pro.txt",
            "content": """
Laptop Pro X1
Prix: 1299‚Ç¨
Processeur: Intel i7 12√®me gen
RAM: 16GB DDR5
SSD: 512GB NVMe
√âcran: 15.6" Full HD
Autonomie: 8 heures
Poids: 1.8kg
Garantie: 2 ans
            """
        },
        {
            "name": "laptop_gaming.txt",
            "content": """
Gaming Beast Z9
Prix: 1899‚Ç¨
Processeur: AMD Ryzen 9
RAM: 32GB DDR5
SSD: 1TB NVMe
GPU: NVIDIA RTX 4070
√âcran: 17.3" QHD 165Hz
Autonomie: 4 heures
Poids: 2.5kg
Garantie: 3 ans
            """
        },
        {
            "name": "laptop_ultrabook.txt",
            "content": """
Ultrabook Air S3
Prix: 899‚Ç¨
Processeur: Intel i5 12√®me gen
RAM: 8GB DDR4
SSD: 256GB NVMe
√âcran: 13.3" Full HD
Autonomie: 12 heures
Poids: 1.1kg
Garantie: 1 an
            """
        }
    ]
    
    print("üìù Ajout des produits...")
    for product in products:
        rag_helper.add_document_sync(
            dataset="products",
            filename=product["name"],
            content=product["content"].strip(),
            metadata={"category": "laptop"}
        )
        print(f"   ‚úÖ {product['name']}")
    
    print()
    
    # Diff√©rents types de recherches
    searches = [
        "Quel laptop est le plus l√©ger ?",
        "Je cherche un laptop pour le gaming",
        "Quel est le laptop avec la meilleure autonomie ?",
        "Laptop avec 32GB de RAM"
    ]
    
    print("üîç Recherches contextuelles :")
    print()
    
    for search in searches:
        print(f"   Q: {search}")
        
        # Recherche simple pour voir les sources
        sources = await rag_helper.quick_search(
            dataset="products",
            query=search,
            top_k=2
        )
        
        if sources:
            best_match = sources[0]
            similarity = best_match['similarity'] * 100
            print(f"   üéØ Meilleure correspondance: {best_match['filename']} ({similarity:.1f}%)")
        
        print()


# ============================================================
# EXEMPLE 4 : Q&A avec historique
# ============================================================

async def example_conversation():
    """Conversation avec contexte maintenu"""
    
    print("=" * 60)
    print("üí¨ EXEMPLE 4 : Conversation avec contexte")
    print("=" * 60)
    print()
    
    # Documentation √† utiliser
    doc = """
L'Agent Local est un syst√®me d'agent intelligent modulaire.

Architecture:
- Backend FastAPI pour l'API REST
- Orchestrateur pour coordonner les actions
- Connecteurs pour services externes (LLM, recherche, etc.)
- Syst√®me RAG pour la base de connaissances
- Frontend web pour l'interface utilisateur

Fonctionnalit√©s:
- Chat avec historique de conversation
- Recherche web avanc√©e (Google, Brave, DuckDuckGo)
- Ex√©cution de code Python
- Gestion de fichiers
- Syst√®me de m√©moire persistante
- RAG avec LLM local (Ollama/LM Studio)

Technologies:
- Python 3.11+
- FastAPI pour l'API
- SQLite pour la persistance
- Gemini API pour les embeddings
- Ollama/LM Studio pour le LLM local
    """
    
    print("üìù Ajout de la documentation...")
    rag_helper.add_document_sync(
        dataset="agent_docs",
        filename="architecture.txt",
        content=doc.strip()
    )
    print("   ‚úÖ Documentation ajout√©e")
    print()
    
    # S√©rie de questions li√©es
    conversation = [
        "Qu'est-ce que l'Agent Local ?",
        "Quels sont ses composants principaux ?",
        "Quelles technologies utilise-t-il ?",
        "Comment fonctionne le syst√®me RAG ?"
    ]
    
    print("üí¨ Conversation :")
    print()
    
    for i, question in enumerate(conversation, 1):
        print(f"   [{i}] Utilisateur: {question}")
        
        answer = await answer_question_with_rag(
            dataset="agent_docs",
            question=question,
            top_k=3
        )
        
        print(f"   [{i}] Agent: {answer}")
        print()


# ============================================================
# EXEMPLE 5 : Statistiques et analytics
# ============================================================

def example_analytics():
    """Analyser les datasets et documents"""
    
    print("=" * 60)
    print("üìä EXEMPLE 5 : Statistiques et analytics")
    print("=" * 60)
    print()
    
    datasets = rag_helper.get_datasets()
    
    if not datasets:
        print("   ‚ÑπÔ∏è  Aucun dataset disponible")
        return
    
    print(f"üìÅ {len(datasets)} dataset(s) disponible(s):")
    print()
    
    total_docs = 0
    total_chunks = 0
    
    for dataset in datasets:
        info = rag_helper.get_dataset_info(dataset)
        total_docs += info['document_count']
        total_chunks += info['chunk_count']
        
        print(f"   üì¶ {dataset}")
        print(f"      Documents: {info['document_count']}")
        print(f"      Chunks: {info['chunk_count']}")
        print(f"      Ratio: {info['chunk_count'] / max(info['document_count'], 1):.1f} chunks/doc")
        
        # Lister les documents
        if info['documents']:
            print(f"      Fichiers:")
            for doc in info['documents'][:3]:  # Top 3
                print(f"         - {doc['filename']}")
            if len(info['documents']) > 3:
                print(f"         ... et {len(info['documents']) - 3} autres")
        
        print()
    
    print("=" * 60)
    print(f"üìà Total: {total_docs} documents, {total_chunks} chunks")
    print("=" * 60)


# ============================================================
# MAIN
# ============================================================

async def main():
    """Ex√©cute tous les exemples"""
    
    print()
    print("üéØ EXEMPLES AVANC√âS - MODULE RAG")
    print()
    
    try:
        # V√©rifier que le LLM est disponible
        llm_ok = await rag_helper.check_llm_available()
        if not llm_ok:
            print("‚ö†Ô∏è  LLM local non disponible - certains exemples seront limit√©s")
            print("   Lancez Ollama ou LM Studio pour une d√©mo compl√®te")
            print()
        
        # Ex√©cuter les exemples
        await example_knowledge_base()
        await example_code_documentation()
        await example_contextual_search()
        await example_conversation()
        example_analytics()
        
        print()
        print("‚úÖ TOUS LES EXEMPLES TERMIN√âS")
        print()
        print("üí° Prochaines √©tapes:")
        print("   - Testez l'interface web: http://localhost:8000/ui/rag.html")
        print("   - Ajoutez vos propres documents: python add_to_rag.py --help")
        print("   - Consultez la doc: RAG_README.md")
        print()
        
    except Exception as e:
        print(f"‚ùå Erreur: {e}")
        import traceback
        traceback.print_exc()


if __name__ == "__main__":
    asyncio.run(main())
